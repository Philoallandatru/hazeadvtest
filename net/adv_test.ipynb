{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from models import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as tfs\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totensor = T.ToTensor()\n",
    "topil = T.ToPILImage()\n",
    "\n",
    "def clamp(X, lower_limit, upper_limit):\n",
    "    return torch.max(torch.min(X, upper_limit), lower_limit)\n",
    "\n",
    "def tensorShow(tensors, titles=['haze']):\n",
    "    fig = plt.figure()\n",
    "    for tensor, tit, i in zip(tensors, titles, range(len(tensors))):\n",
    "        img = make_grid(tensor)\n",
    "        npimg = img.numpy()\n",
    "        ax = fig.add_subplot(221+i)\n",
    "        ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        ax.set_title(tit)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# abs=os.getcwd()+'/'\n",
    "abs = os.getcwd()+'\\\\'\n",
    "\n",
    "\n",
    "dataset = \"ots\"\n",
    "gps = 3\n",
    "blocks = 19\n",
    "\n",
    "\n",
    "\n",
    "# model_dir=abs+f'trained_models/{dataset}_train_ffa_{gps}_{blocks}.pk'\n",
    "model_dir = abs + f'trained_models\\\\{dataset}_train_ffa_{gps}_{blocks}.pk'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ckp = torch.load(model_dir, map_location=device)\n",
    "net = FFA(gps=gps, blocks=blocks)\n",
    "net = nn.DataParallel(net)\n",
    "net.load_state_dict(ckp['model'])\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_mean = (0.0, 0.0, 0.0)\n",
    "cifar10_std = (1.0, 1.0, 1.0)\n",
    "mu = torch.tensor(cifar10_mean).view(3,1,1).cuda()\n",
    "std = torch.tensor(cifar10_std).view(3,1,1).cuda()\n",
    "\n",
    "epsilon = 8\n",
    "start_epsilon = 8\n",
    "step_alpha = 2\n",
    "seed = 160\n",
    "num_img = 20\n",
    "attack_iter = 50\n",
    "\n",
    "upper_limit = ((1 - mu) / std)\n",
    "lower_limit = ((0 - mu) / std)\n",
    "\n",
    "epsilon = (epsilon / 255.) / std\n",
    "start_epsilon = (start_epsilon / 255.) / std\n",
    "step_alpha = (step_alpha / 255.) / std\n",
    "\n",
    "image_path = \"test_imgs/1400_2.png\"\n",
    "input_image = Image.open(image_path)\n",
    "input_image = torch.unsqueeze(totensor(input_image).cuda(), 0)\n",
    "delta = torch.zeros_like(input_image).cuda()\n",
    "delta.requires_grad = True\n",
    "\n",
    "clean_image = input_image\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(attack_iter):\n",
    "    k += 1\n",
    "    dehazed_image = net(clean_image + delta)\n",
    "\n",
    "    # wanna the dehazed output similar to the orginal, which means the model does nothing\n",
    "    loss = F.mse_loss(clean_image.data, dehazed_image.float())\n",
    "    loss.backward()\n",
    "    grad = delta.grad.detach()\n",
    "    d = delta\n",
    "    d = clamp(d + step_alpha * torch.sign(grad), -epsilon, epsilon)\n",
    "    delta.data = d\n",
    "    delta.grad.zero_()\n",
    "\n",
    "adv_image = clamp(clean_image + delta, lower_limit, upper_limit)\n",
    "adv_image = torch.unsqueeze(adv_image.cuda(), 0)\n",
    "adv_output = net(adv_image)\n",
    "clean_output = net(input_image)\n",
    "\n",
    "save_image(torch.cat((adv_output, adv_image, clean_output, input_image),0), \"adv_output/\" + \"zero_output2_\" + image_path.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
