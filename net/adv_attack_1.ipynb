{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from models import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as tfs\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "totensor = T.ToTensor()\n",
    "topil = T.ToPILImage()\n",
    "\n",
    "def recover_image(image, init_image, mask, background=False):\n",
    "    image = totensor(image)\n",
    "    mask = totensor(mask)\n",
    "    init_image = totensor(init_image)\n",
    "    if background:\n",
    "        result = mask * init_image + (1 - mask) * image\n",
    "    else:\n",
    "        result = mask * image + (1 - mask) * init_image\n",
    "    return topil(result)\n",
    "\n",
    "def preprocess(image):\n",
    "    w, h = image.size\n",
    "    w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n",
    "    image = image.resize((w, h), resample=Image.LANCZOS)\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = image[None].transpose(0, 3, 1, 2)\n",
    "    image = torch.from_numpy(image)\n",
    "    return 2.0 * image - 1.0\n",
    "\n",
    "def prepare_mask_and_masked_image(image, mask):\n",
    "    image = np.array(image.convert(\"RGB\"))\n",
    "    image = image[None].transpose(0, 3, 1, 2)\n",
    "    image = torch.from_numpy(image).to(dtype=torch.float32) / 127.5 - 1.0\n",
    "\n",
    "    mask = np.array(mask.convert(\"L\"))\n",
    "    mask = mask.astype(np.float32) / 255.0\n",
    "    mask = mask[None, None]\n",
    "    mask[mask < 0.5] = 0\n",
    "    mask[mask >= 0.5] = 1\n",
    "    mask = torch.from_numpy(mask)\n",
    "\n",
    "    masked_image = image * (mask < 0.5)\n",
    "\n",
    "    return mask, masked_image\n",
    "\n",
    "def prepare_image(image):\n",
    "    image = np.array(image.convert(\"RGB\"))\n",
    "    image = image[None].transpose(0, 3, 1, 2)\n",
    "    image = torch.from_numpy(image).to(dtype=torch.float32) / 127.5 - 1.0\n",
    "\n",
    "    return image[0]\n",
    "\n",
    "def clamp(X, lower_limit, upper_limit):\n",
    "    return torch.max(torch.min(X, upper_limit), lower_limit)\n",
    "\n",
    "def tensorShow(tensors, titles=['haze']):\n",
    "    fig = plt.figure()\n",
    "    for tensor, tit, i in zip(tensors, titles, range(len(tensors))):\n",
    "        img = make_grid(tensor)\n",
    "        npimg = img.numpy()\n",
    "        ax = fig.add_subplot(221+i)\n",
    "        ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        ax.set_title(tit)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# abs=os.getcwd()+'/'\n",
    "abs = os.getcwd()+'\\\\'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--task', type=str, default='its', help='its or ots')\n",
    "parser.add_argument('--test_imgs', type=str,\n",
    "                    default='test_imgs', help='Test imgs folder')\n",
    "opt = parser.parse_args()\n",
    "\n",
    "\n",
    "opt.task = \"ots\"\n",
    "opt.test_imgs = \"test_imgs\"\n",
    "\n",
    "dataset = opt.task\n",
    "gps = 3\n",
    "blocks = 19\n",
    "\n",
    "# img_dir=abs+opt.test_imgs+'/'\n",
    "img_dir = abs + opt.test_imgs+'\\\\'\n",
    "\n",
    "# output_dir=abs+f'pred_FFA_{dataset}/'\n",
    "output_dir = abs + f'pred_FFA_{dataset}\\\\'\n",
    "\n",
    "print(\"pred_dir:\", output_dir)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# model_dir=abs+f'trained_models/{dataset}_train_ffa_{gps}_{blocks}.pk'\n",
    "model_dir = abs + f'trained_models\\\\{dataset}_train_ffa_{gps}_{blocks}.pk'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ckp = torch.load(model_dir, map_location=device)\n",
    "net = FFA(gps=gps, blocks=blocks)\n",
    "net = nn.DataParallel(net)\n",
    "net.load_state_dict(ckp['model'])\n",
    "net.eval()\n",
    "\n",
    "\n",
    "for im in os.listdir(img_dir):\n",
    "    print(f'\\r {im}', end='', flush=True)\n",
    "    haze = Image.open(img_dir+im)\n",
    "    haze1 = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.64, 0.6, 0.58], std=[0.14, 0.15, 0.152])\n",
    "    ])(haze)[None, ::]\n",
    "    haze_no = T.ToTensor()(haze)[None, ::]\n",
    "    with torch.no_grad():\n",
    "        pred = net(haze1)\n",
    "    ts = torch.squeeze(pred.clamp(0, 1).cpu())\n",
    "    tensorShow([haze_no, pred.clamp(0, 1).cpu()], ['haze', 'pred'])\n",
    "    vutils.save_image(ts, output_dir+im.split('.')[0]+'_FFA.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): FFA(\n",
       "    (g1): Group(\n",
       "      (gp): Sequential(\n",
       "        (0): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (13): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (15): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (16): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (17): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (19): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (g2): Group(\n",
       "      (gp): Sequential(\n",
       "        (0): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (13): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (15): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (16): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (17): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (19): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (g3): Group(\n",
       "      (gp): Sequential(\n",
       "        (0): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (13): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (15): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (16): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (17): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): Block(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (calayer): CALayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (ca): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (palayer): PALayer(\n",
       "            (pa): Sequential(\n",
       "              (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (19): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (ca): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=1)\n",
       "      (1): Conv2d(192, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(4, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "    (palayer): PALayer(\n",
       "      (pa): Sequential(\n",
       "        (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (pre): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (post): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abs=os.getcwd()+'/'\n",
    "abs = os.getcwd()+'\\\\'\n",
    "\n",
    "\n",
    "dataset = \"ots\"\n",
    "gps = 3\n",
    "blocks = 19\n",
    "\n",
    "\n",
    "\n",
    "# model_dir=abs+f'trained_models/{dataset}_train_ffa_{gps}_{blocks}.pk'\n",
    "model_dir = abs + f'trained_models\\\\{dataset}_train_ffa_{gps}_{blocks}.pk'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ckp = torch.load(model_dir, map_location=device)\n",
    "net = FFA(gps=gps, blocks=blocks)\n",
    "net = nn.DataParallel(net)\n",
    "net.load_state_dict(ckp['model'])\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 6.00 GiB total capacity; 5.32 GiB already allocated; 0 bytes free; 5.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32me:\\Code\\python\\adversarial\\dehazing\\FFA-Net-master\\net\\adv_attack_1.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Code/python/adversarial/dehazing/FFA-Net-master/net/adv_attack_1.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(attack_iter):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Code/python/adversarial/dehazing/FFA-Net-master/net/adv_attack_1.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     k \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Code/python/adversarial/dehazing/FFA-Net-master/net/adv_attack_1.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     dehazed_image \u001b[39m=\u001b[39m net(clean_image \u001b[39m+\u001b[39;49m delta)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Code/python/adversarial/dehazing/FFA-Net-master/net/adv_attack_1.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# wanna the dehazed output similar to the orginal, which means the model does nothing\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Code/python/adversarial/dehazing/FFA-Net-master/net/adv_attack_1.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(clean_image\u001b[39m.\u001b[39mdata, dehazed_image\u001b[39m.\u001b[39mfloat())\n",
      "File \u001b[1;32mc:\\Users\\10259\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\10259\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py:166\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m     kwargs \u001b[39m=\u001b[39m ({},)\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs[\u001b[39m0\u001b[39m])\n\u001b[0;32m    167\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[0;32m    168\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel_apply(replicas, inputs, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\10259\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Code\\python\\adversarial\\dehazing\\FFA-Net-master\\net\\models\\FFA.py:92\u001b[0m, in \u001b[0;36mFFA.forward\u001b[1;34m(self, x1)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x1):\n\u001b[0;32m     91\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre(x1)\n\u001b[1;32m---> 92\u001b[0m     res1\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mg1(x)\n\u001b[0;32m     93\u001b[0m     res2\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg2(res1)\n\u001b[0;32m     94\u001b[0m     res3\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg3(res2)\n",
      "File \u001b[1;32mc:\\Users\\10259\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Code\\python\\adversarial\\dehazing\\FFA-Net-master\\net\\models\\FFA.py:59\u001b[0m, in \u001b[0;36mGroup.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 59\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgp(x)\n\u001b[0;32m     60\u001b[0m     res \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m x\n\u001b[0;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\10259\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\10259\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\10259\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Code\\python\\adversarial\\dehazing\\FFA-Net-master\\net\\models\\FFA.py:49\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     47\u001b[0m res\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(res)\n\u001b[0;32m     48\u001b[0m res\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalayer(res)\n\u001b[1;32m---> 49\u001b[0m res\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpalayer(res)\n\u001b[0;32m     50\u001b[0m res \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m x \n\u001b[0;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\10259\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Code\\python\\adversarial\\dehazing\\FFA-Net-master\\net\\models\\FFA.py:18\u001b[0m, in \u001b[0;36mPALayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     17\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpa(x)\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m*\u001b[39;49m y\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 6.00 GiB total capacity; 5.32 GiB already allocated; 0 bytes free; 5.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cifar10_mean = (0.0, 0.0, 0.0)\n",
    "cifar10_std = (1.0, 1.0, 1.0)\n",
    "mu = torch.tensor(cifar10_mean).view(3,1,1).cuda()\n",
    "std = torch.tensor(cifar10_std).view(3,1,1).cuda()\n",
    "\n",
    "epsilon = 8\n",
    "start_epsilon = 8\n",
    "step_alpha = 2\n",
    "seed = 160\n",
    "num_img = 20\n",
    "attack_iter = 50\n",
    "\n",
    "upper_limit = ((1 - mu) / std)\n",
    "lower_limit = ((0 - mu) / std)\n",
    "\n",
    "epsilon = (epsilon / 255.) / std\n",
    "start_epsilon = (start_epsilon / 255.) / std\n",
    "step_alpha = (step_alpha / 255.) / std\n",
    "\n",
    "input_image = Image.open(\"test_imgs/1400_2.png\")\n",
    "input_image = torch.unsqueeze(totensor(input_image).cuda(), 0)\n",
    "delta = torch.zeros_like(input_image).cuda()\n",
    "delta.requires_grad = True\n",
    "\n",
    "clean_image = input_image\n",
    "\n",
    "for k in range(attack_iter):\n",
    "    k += 1\n",
    "    dehazed_image = net(clean_image + delta)\n",
    "\n",
    "    # wanna the dehazed output similar to the orginal, which means the model does nothing\n",
    "    loss = F.mse_loss(clean_image.data, dehazed_image.float())\n",
    "    loss.backward()\n",
    "    grad = delta.grad.detach()\n",
    "    d = delta\n",
    "    d = clamp(d + step_alpha * torch.sign(grad), -epsilon, epsilon)\n",
    "    delta.data = d\n",
    "    delta.grad.zero_()\n",
    "\n",
    "adv_image = clamp(clean_image + delta, lower_limit, upper_limit)\n",
    "adv_image = torch.unsqueeze(adv_image.cuda(), 0)\n",
    "adv_output = net(adv_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(X, model, eps=0.1, step_size=0.015, iters=40, clamp_min=0, clamp_max=1, mask=None):\n",
    "    X_adv = X.clone().detach() + (torch.rand(*X.shape)*2*eps-eps).cuda()\n",
    "    pbar = tqdm(range(iters))\n",
    "    for i in pbar:\n",
    "        actual_step_size = step_size - \\\n",
    "            (step_size - step_size / 100) / iters * i\n",
    "\n",
    "        X_adv.requires_grad_(True)\n",
    "\n",
    "        loss = (model(X_adv).latent_dist.mean).norm()\n",
    "\n",
    "        pbar.set_description(\n",
    "            f\"[Running attack]: Loss {loss.item():.5f} | step size: {actual_step_size:.4}\")\n",
    "\n",
    "        grad, = torch.autograd.grad(loss, [X_adv])\n",
    "\n",
    "        X_adv = X_adv - grad.detach().sign() * actual_step_size\n",
    "        X_adv = torch.minimum(torch.maximum(X_adv, X - eps), X + eps)\n",
    "        X_adv.data = torch.clamp(X_adv, min=clamp_min, max=clamp_max)\n",
    "        X_adv.grad = None\n",
    "\n",
    "        if mask is not None:\n",
    "            X_adv.data *= mask\n",
    "\n",
    "    return X_adv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autocast('cuda'):\n",
    "    X = preprocess(init_image).half().cuda()\n",
    "    adv_X = pgd(X, \n",
    "                model=net, \n",
    "                clamp_min=-1, \n",
    "                clamp_max=1,\n",
    "                eps=0.06, # The higher, the less imperceptible the attack is \n",
    "                step_size=0.02, # Set smaller than eps\n",
    "                iters=100, # The higher, the stronger your attack will be\n",
    "               )\n",
    "    \n",
    "    # convert pixels back to [0,1] range\n",
    "    adv_X = (adv_X / 2 + 0.5).clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_image = recover_image(adv_image, init_image, mask_image, background=True)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(20,6))\n",
    "\n",
    "ax[0].imshow(clean_image)\n",
    "ax[1].imshow(adv_image)\n",
    "\n",
    "ax[0].set_title('Source Image', fontsize=16)\n",
    "ax[1].set_title('Adv Image', fontsize=16)\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].grid(False)\n",
    "    ax[i].axis('off')\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b84c0a872f08c3621143952d626e363b388143aa89ed2e6ffd2f8793228d1f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
